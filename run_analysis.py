#!/usr/bin/env python3
"""
GeoGov Analysis Runner
Processes dynamic inputs and runs comprehensive compliance analysis
"""

import asyncio
import json
import os
import yaml
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

import httpx
import pandas as pd

# Import from our integrated system
from main import (
    FeatureArtifact, Decision, Settings,
    scraping_aggregator, analyze, evidence_system
)


class AnalysisRunner:
    """Orchestrates the complete compliance analysis workflow"""
    
    def __init__(self):
        self.settings = Settings()
        self.results = []
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    async def load_inputs(self, inputs_file: str = "inputs.yaml") -> Dict[str, Any]:
        """Load dynamic inputs from YAML configuration"""
        try:
            with open(inputs_file, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"‚ùå Input file {inputs_file} not found")
            raise
        except yaml.YAMLError as e:
            print(f"‚ùå Error parsing {inputs_file}: {e}")
            raise
    
    async def refresh_knowledge_base(self, regulations: List[Dict], force_refresh: bool = False, skip_scraping: bool = False) -> Dict[str, Any]:
        """Refresh the knowledge base with regulation research"""
        if skip_scraping:
            print(f"\n‚è≠Ô∏è  Skipping knowledge base refresh - using existing vector store only")
            return {"ingested": 0, "skipped": True, "message": "Scraping skipped"}
        
        refresh_type = "force refresh" if force_refresh else "smart refresh"
        print(f"\nüîÑ {refresh_type.title()} of knowledge base with {len(regulations)} regulations...")
        
        try:
            result = await scraping_aggregator.refresh_corpus_for_regulations(regulations, force_refresh=force_refresh)
            print(f"‚úÖ Knowledge base refreshed: {result['ingested']} documents indexed")
            return result
        except Exception as e:
            print(f"‚ö†Ô∏è  Knowledge base refresh failed: {e}")
            return {"ingested": 0, "error": str(e)}
    
    async def analyze_feature(self, feature_config: Dict) -> Decision:
        """Analyze a single feature for compliance"""
        # Convert config to FeatureArtifact
        feature = FeatureArtifact(
            feature_id=feature_config["feature_id"],
            title=feature_config["title"],
            description=feature_config["description"],
            docs=feature_config.get("docs", []),
            code_hints=feature_config.get("code_hints", []),
            tags=feature_config.get("tags", [])
        )
        
        print(f"\nüîç Analyzing: {feature.feature_id} - {feature.title}")
        
        try:
            decision = await analyze(feature)
            
            # Validate against expected results if provided
            expected_compliance = feature_config.get("expected_compliance")
            expected_regulations = feature_config.get("expected_regulations", [])
            
            validation_notes = []
            if expected_compliance is not None:
                compliance_match = decision.needs_geo_compliance == expected_compliance
                validation_notes.append(f"Compliance prediction: {'‚úÖ' if compliance_match else '‚ùå'} (expected: {expected_compliance}, got: {decision.needs_geo_compliance})")
            
            if expected_regulations:
                regulation_match = bool(set(expected_regulations) & set(decision.regulations))
                validation_notes.append(f"Regulations match: {'‚úÖ' if regulation_match else '‚ùå'} (expected: {expected_regulations}, got: {decision.regulations})")
            
            # Add validation to decision metadata
            if hasattr(decision, 'metadata'):
                decision.metadata.update({"validation_notes": validation_notes})
            
            print(f"   üìä Result: {'üö® COMPLIANCE REQUIRED' if decision.needs_geo_compliance else '‚úÖ NO COMPLIANCE NEEDED'}")
            print(f"   üìè Confidence: {decision.confidence:.2f}")
            print(f"   üìã Regulations: {', '.join(decision.regulations) if decision.regulations else 'None'}")
            
            if validation_notes:
                print(f"   üîç Validation:")
                for note in validation_notes:
                    print(f"      {note}")
            
            return decision
            
        except Exception as e:
            print(f"‚ùå Analysis failed for {feature.feature_id}: {e}")
            # Create a failure decision
            return Decision(
                feature_id=feature.feature_id,
                needs_geo_compliance=False,
                reasoning=f"Analysis failed: {str(e)}",
                regulations=[],
                signals=[],
                citations=[],
                confidence=0.0,
                matched_rules=[]
            )
    
    async def run_batch_analysis(self, features: List[Dict]) -> List[Decision]:
        """Run analysis on multiple features"""
        print(f"\nüéØ Running batch analysis on {len(features)} features...")
        
        decisions = []
        
        for feature_config in features:
            decision = await self.analyze_feature(feature_config)
            decisions.append(decision)
            self.results.append({
                "session_id": self.session_id,
                "timestamp": datetime.now().isoformat(),
                "feature_id": decision.feature_id,
                "needs_compliance": decision.needs_geo_compliance,
                "regulations": decision.regulations,
                "confidence": decision.confidence,
                "reasoning": decision.reasoning
            })
        
        return decisions
    
    def generate_summary_report(self, decisions: List[Decision], features: List[Dict]) -> Dict[str, Any]:
        """Generate a summary report of the analysis"""
        total_features = len(decisions)
        compliance_required = sum(1 for d in decisions if d.needs_geo_compliance)
        
        # Regulation frequency analysis
        regulation_counts = {}
        for decision in decisions:
            for reg in decision.regulations:
                regulation_counts[reg] = regulation_counts.get(reg, 0) + 1
        
        # Confidence analysis
        avg_confidence = sum(d.confidence for d in decisions) / total_features if total_features > 0 else 0
        
        # Validation results if available
        validation_summary = {"correct_predictions": 0, "total_validatable": 0}
        for i, decision in enumerate(decisions):
            if i < len(features):
                feature_config = features[i]
                expected = feature_config.get("expected_compliance")
                if expected is not None:
                    validation_summary["total_validatable"] += 1
                    if decision.needs_geo_compliance == expected:
                        validation_summary["correct_predictions"] += 1
        
        accuracy = 0
        if validation_summary["total_validatable"] > 0:
            accuracy = validation_summary["correct_predictions"] / validation_summary["total_validatable"]
        
        return {
            "session_id": self.session_id,
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_features_analyzed": total_features,
                "features_requiring_compliance": compliance_required,
                "compliance_rate": compliance_required / total_features if total_features > 0 else 0,
                "average_confidence": avg_confidence,
                "prediction_accuracy": accuracy
            },
            "regulation_frequency": regulation_counts,
            "validation": validation_summary
        }
    
    async def export_results(self, decisions: List[Decision], summary: Dict[str, Any]):
        """Export results to various formats"""
        print(f"\nüìä Exporting results...")
        
        # Export to CSV using the evidence system
        csv_path = evidence_system.export_csv(decisions, f"data/analysis_results_{self.session_id}.csv")
        print(f"   üìÑ CSV exported: {csv_path}")
        
        # Export summary as JSON
        summary_path = f"data/analysis_summary_{self.session_id}.json"
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        print(f"   üìÑ Summary exported: {summary_path}")
        
        # Create evidence ZIP
        try:
            zip_path = f"analysis_evidence_{self.session_id}.zip"
            zip_data = evidence_system.make_evidence_zip()
            with open(zip_path, 'wb') as f:
                f.write(zip_data)
            print(f"   üì¶ Evidence ZIP created: {zip_path}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Failed to create evidence ZIP: {e}")
        
        return {
            "csv_path": csv_path,
            "summary_path": summary_path,
            "zip_path": zip_path if 'zip_path' in locals() else None
        }
    
    async def run_complete_analysis(self, inputs_file: str = "inputs.yaml", force_refresh: bool = False, skip_scraping: bool = False):
        """Run the complete analysis workflow"""
        print(f"üöÄ Starting GeoGov Analysis - Session: {self.session_id}")
        print("=" * 60)
        
        try:
            # Load inputs
            inputs = await self.load_inputs(inputs_file)
            regulations = inputs.get("regulations", [])
            test_features = inputs.get("test_features", [])
            
            if not test_features:
                print("‚ùå No test features found in inputs")
                return
            
            # Refresh knowledge base if regulations are provided
            kb_result = None
            if regulations:
                kb_result = await self.refresh_knowledge_base(regulations, force_refresh=force_refresh, skip_scraping=skip_scraping)
            
            # Run analysis
            decisions = await self.run_batch_analysis(test_features)
            
            # Generate summary
            summary = self.generate_summary_report(decisions, test_features)
            
            # Export results
            export_paths = await self.export_results(decisions, summary)
            
            # Print final summary
            print(f"\nüéâ Analysis Complete!")
            print("=" * 60)
            print(f"üìä Features Analyzed: {summary['summary']['total_features_analyzed']}")
            print(f"üö® Compliance Required: {summary['summary']['features_requiring_compliance']} ({summary['summary']['compliance_rate']:.1%})")
            print(f"üéØ Average Confidence: {summary['summary']['average_confidence']:.2f}")
            if summary['summary']['prediction_accuracy'] > 0:
                print(f"‚úÖ Prediction Accuracy: {summary['summary']['prediction_accuracy']:.1%}")
            
            if summary['regulation_frequency']:
                print(f"\nüìã Most Triggered Regulations:")
                sorted_regs = sorted(summary['regulation_frequency'].items(), key=lambda x: x[1], reverse=True)
                for reg, count in sorted_regs[:5]:
                    print(f"   ‚Ä¢ {reg}: {count} features")
            
            print(f"\nüìÅ Results exported to:")
            print(f"   ‚Ä¢ {export_paths['csv_path']}")
            print(f"   ‚Ä¢ {export_paths['summary_path']}")
            if export_paths['zip_path']:
                print(f"   ‚Ä¢ {export_paths['zip_path']}")
            
            return {
                "decisions": decisions,
                "summary": summary,
                "export_paths": export_paths
            }
            
        except Exception as e:
            print(f"‚ùå Analysis failed: {e}")
            raise
        finally:
            # Cleanup
            await scraping_aggregator.close()


# CLI Interface
async def main():
    """Main CLI interface"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Run GeoGov compliance analysis")
    parser.add_argument("--inputs", "-i", default="inputs.yaml", help="Input configuration file")
    parser.add_argument("--feature", "-f", help="Analyze single feature by ID")
    parser.add_argument("--export-only", action="store_true", help="Only export existing results")
    parser.add_argument("--force-refresh", action="store_true", help="Force re-embedding of all documents even if they exist")
    parser.add_argument("--use-rules-engine", action="store_true", help="Use rules engine for final decision instead of LLM (default is LLM)")
    parser.add_argument("--skip-indexing", action="store_true", help="Skip adding new documents to vector store (use existing index only)")
    parser.add_argument("--skip-scraping", action="store_true", help="Skip scraping documents entirely (use existing vector store only)")
    
    args = parser.parse_args()
    
    runner = AnalysisRunner()
    
    # Override settings based on flags
    from main import settings
    
    if args.use_rules_engine:
        settings.use_rules_engine = True
        print("üîß Using rules engine for final compliance decisions instead of LLM")
    else:
        print("ü§ñ Using LLM for final compliance decisions (default)")
        
    if args.skip_indexing:
        settings.skip_indexing = True
        print("‚è≠Ô∏è  Skipping vector store indexing - using existing index only")
        
    if args.skip_scraping:
        settings.skip_scraping = True
        print("‚è≠Ô∏è  Skipping document scraping - using existing vector store only")
    
    if args.export_only:
        print("üìä Export mode - processing existing data...")
        # TODO: Implement export-only mode
        return
    
    if args.feature:
        # Single feature analysis
        inputs = await runner.load_inputs(args.inputs)
        features = inputs.get("test_features", [])
        
        target_feature = next((f for f in features if f.get("feature_id") == args.feature), None)
        if not target_feature:
            print(f"‚ùå Feature {args.feature} not found in inputs")
            return
        
        decision = await runner.analyze_feature(target_feature)
        print(f"\n‚úÖ Analysis complete for {decision.feature_id}")
    else:
        # Full batch analysis
        await runner.run_complete_analysis(args.inputs, force_refresh=args.force_refresh, skip_scraping=args.skip_scraping)


if __name__ == "__main__":
    asyncio.run(main())